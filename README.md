Projeto de machine learning com o objetivo de prever se Kobe Bryant acertou ou errou uma tentativa de arremesso, utilizando abordagens de classifica√ß√£o e regress√£o. O projeto √© baseado no dataset [Kobe Bryant Shot Selectio](https://www.kaggle.com/c/kobe-bryant-shot-selection/overview), dispon√≠vel no Kaggle.

```mermaid
flowchart
    subgraph data_ingestion[pipeline: data_ingestion]
        direction TB
        subgraph data_ingestion_nodes[nodes]
            direction LR
            download_kobe_shots_dev_dataset[node: download_kobe_shots_dev_dataset]
            download_kobe_shots_prod_dataset[node: download_kobe_shots_prod_dataset]
        end
        subgraph data_ingestion_outputs[outputs]
            direction LR
            raw_kobe_shots_dev_dataset{{output 'raw_kobe_shots_dev': data/01_raw/dataset_kobe_dev.parquet}}
            raw_kobe_shots_prod_dataset{{output 'raw_kobe_shots_prod': data/01_raw/dataset_kobe_prod.parquet}}
        end
        download_kobe_shots_dev_dataset --> raw_kobe_shots_dev_dataset
        download_kobe_shots_prod_dataset --> raw_kobe_shots_prod_dataset
    end
    subgraph data_processing[pipeline: data_processing]
        direction TB
        subgraph data_processing_nodes[nodes]
            direction LR
            preprocess_kobe_shots_dev_node[node: preprocess_kobe_shots]
            preprocess_kobe_shots_prod_node[node: preprocess_kobe_shots_prod]
            create_model_input_table_node[node: create_model_input_table_node]
            split_data_node[node: split_data_node]
        end
        subgraph data_processing_outputs[outputs]
            direction LR
            preprocessed_kobe_shots[output 'preprocessed_kobe_shots': data/02_intermediate/preprocessed_kobe_shots.parquet]
            preprocessed_kobe_shots_prod[output 'preprocessed_kobe_shots_prod': data/02_intermediate/preprocessed_kobe_shots.parquet]
            model_input_table[output 'model_input_table': data/03_primary/data_filtered.parquet]
            base_train[output 'base_train': data/03_primary/data_filtered.parquet]
            base_test[output 'base_test': data/03_primary/data_filtered.parquet]
        end
        preprocess_kobe_shots_dev_node --> preprocessed_kobe_shots
        preprocess_kobe_shots_prod_node --> preprocessed_kobe_shots_prod
        create_model_input_table_node --> model_input_table
        split_data_node --> base_train
        split_data_node --> base_test
    end
    subgraph data_science[pipeline: data_science]
        direction TB
        subgraph data_science_nodes[nodes]
            direction LR
            train_logistic_regression_model_node[node: train_logistic_regression_model_node]
            train_decision_tree_model_node[node: train_decision_tree_model_node]
            save_logistic_regression_model_plots_node[node: save_logistic_regression_model_plots_node]
            save_decision_tree_model_plots_node[node: save_decision_tree_model_plots_node]
        end
        subgraph data_science_outputs[outputs]
            direction LR
            logistic_regression_model[output 'logistic_regression_model': logistic-regression-model]
            logistic_regression_model_with_proba[output 'logistic_regression_model_with_proba': logistic-regression-model-dev]
            decision_tree_model[output 'decision_tree_model': decision-tree-model]
            logistic_regression_model_auc[output 'logistic_regression_model_auc': data/08_reporting/logistic_regression_model_auc.png]
            logistic_regression_model_confusion_matrix[output 'logistic_regression_model_confusion_matrix': data/08_reporting/logistic_regression_model_confusion_matrix.png]
            logistic_regression_model_feature_importance[output 'logistic_regression_model_feature_importance': data/08_reporting/logistic_regression_model_feature_importance.png]
            decision_tree_auc[output 'decision_tree_auc': data/08_reporting/decision_tree_model_auc.png]
            decision_tree_model_confusion_matrix[output 'decision_tree_model_confusion_matrix': data/08_reporting/decision_tree_model_confusion_matrix.png]
            decision_tree_model_feature_importance[output 'decision_tree_model_feature_importance': data/08_reporting/decision_tree_model_feature_importance.png]
        end
        train_logistic_regression_model_node --> logistic_regression_model
        train_logistic_regression_model_node --> logistic_regression_model_with_proba
        train_decision_tree_model_node --> decision_tree_model
        save_logistic_regression_model_plots_node --> logistic_regression_model_auc
        save_logistic_regression_model_plots_node --> logistic_regression_model_confusion_matrix
        save_logistic_regression_model_plots_node --> logistic_regression_model_feature_importance
        save_decision_tree_model_plots_node --> decision_tree_auc
        save_decision_tree_model_plots_node --> decision_tree_model_confusion_matrix
        save_decision_tree_model_plots_node --> decision_tree_model_feature_importance
    end
    subgraph data_science[pipeline: data_science]
        direction TB
        subgraph data_science_nodes[nodes]
            direction LR
            train_logistic_regression_model_node[node: train_logistic_regression_model_node]
            train_decision_tree_model_node[node: train_decision_tree_model_node]
            save_logistic_regression_model_plots_node[node: save_logistic_regression_model_plots_node]
            save_decision_tree_model_plots_node[node: save_decision_tree_model_plots_node]
        end
        subgraph data_science_outputs[outputs]
            direction LR
            logistic_regression_model[output 'logistic_regression_model': logistic-regression-model]
            logistic_regression_model_with_proba[output 'logistic_regression_model_with_proba': logistic-regression-model-dev]
            decision_tree_model[output 'decision_tree_model': decision-tree-model]
            logistic_regression_model_auc[output 'logistic_regression_model_auc': data/08_reporting/logistic_regression_model_auc.png]
            logistic_regression_model_confusion_matrix[output 'logistic_regression_model_confusion_matrix': data/08_reporting/logistic_regression_model_confusion_matrix.png]
            logistic_regression_model_feature_importance[output 'logistic_regression_model_feature_importance': data/08_reporting/logistic_regression_model_feature_importance.png]
            decision_tree_auc[output 'decision_tree_auc': data/08_reporting/decision_tree_model_auc.png]
            decision_tree_model_confusion_matrix[output 'decision_tree_model_confusion_matrix': data/08_reporting/decision_tree_model_confusion_matrix.png]
            decision_tree_model_feature_importance[output 'decision_tree_model_feature_importance': data/08_reporting/decision_tree_model_feature_importance.png]
        end
        train_logistic_regression_model_node --> logistic_regression_model
        train_logistic_regression_model_node --> logistic_regression_model_with_proba
        train_decision_tree_model_node --> decision_tree_model
        save_logistic_regression_model_plots_node --> logistic_regression_model_auc
        save_logistic_regression_model_plots_node --> logistic_regression_model_confusion_matrix
        save_logistic_regression_model_plots_node --> logistic_regression_model_feature_importance
        save_decision_tree_model_plots_node --> decision_tree_auc
        save_decision_tree_model_plots_node --> decision_tree_model_confusion_matrix
        save_decision_tree_model_plots_node --> decision_tree_model_feature_importance
    end
    data_ingestion --> data_processing
    data_processing --> data_science
```

### Como as ferramentas Streamlit, MLflow, PyCaret e Scikit-Learn auxiliam na constru√ß√£o dos pipelines?

üß™ Rastreamento de Experimentos (Experiment Tracking)

- MLflow √© utilizado para rastrear cada execu√ß√£o (run) dos experimentos, registrando hiperpar√¢metros, m√©tricas (como log_loss e f1_score), artefatos (como o modelo treinado) e vers√µes dos dados e c√≥digo utilizados.
- O Kedro facilita a integra√ß√£o desses experimentos em pipelines reprodut√≠veis e versionados.

‚öôÔ∏è Fun√ß√µes de Treinamento

- PyCaret simplifica a cria√ß√£o, compara√ß√£o, tuning e valida√ß√£o de m√∫ltiplos modelos de classifica√ß√£o com poucas linhas de c√≥digo.
- Scikit-Learn √© utilizado nos bastidores do PyCaret e tamb√©m diretamente para etapas de pr√©-processamento personalizadas ou no p√≥s-processamento.
- As fun√ß√µes de treinamento s√£o integradas ao pipeline do Kedro, que garante modularidade e organiza√ß√£o.

üìà Monitoramento da Sa√∫de do Modelo

- Utilizamos MLflow para registrar m√©tricas de desempenho que ajudam a monitorar a sa√∫de do modelo ao longo do tempo.
- Em produ√ß√£o, a sa√∫de pode ser acompanhada via m√©tricas como log_loss, f1_score, propor√ß√£o de classes previstas, entre outras, comparadas com as dos dados de treino.

üîÅ Atualiza√ß√£o de Modelo

- O pipeline foi estruturado para permitir reexecu√ß√µes programadas ou sob demanda (reativo ou preditivo).
- Altera√ß√µes no conjunto de dados de produ√ß√£o podem ser detectadas com data drift e model drift, sinalizando a necessidade de retreinamento.
- O modelo pode ser atualizado automaticamente com novos dados rotulados, com logs completos sendo mantidos pelo MLflow.

üöÄ Provisionamento (Deployment)

- O modelo √© versionado e registrado no MLflow Model Registry.
- Pode ser servido via API local com mlflow models serve ou embarcado diretamente na aplica√ß√£o Streamlit, garantindo infer√™ncia direta.
- A interface desenvolvida em Streamlit permite intera√ß√£o com o modelo, visualiza√ß√£o dos dados e resultados das previs√µes.
