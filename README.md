Projeto de machine learning com o objetivo de prever se Kobe Bryant acertou ou errou uma tentativa de arremesso, utilizando abordagens de classifica√ß√£o e regress√£o. O projeto √© baseado no dataset [Kobe Bryant Shot Selectio](https://www.kaggle.com/c/kobe-bryant-shot-selection/overview), dispon√≠vel no Kaggle.

# Diagrama

Abaixo encontra-se o diagrama contendo todas as etapas necess√°rias para este projeto que vai desde a pipeline de aquisi√ß√£o at√© a opera√ß√£o do modelo:

```mermaid
flowchart
    subgraph data_ingestion[pipeline: data_ingestion]
        direction TB
        subgraph data_ingestion_nodes[nodes]
            direction LR
            download_kobe_shots_dev_dataset[node: download_kobe_shots_dev_dataset]
            download_kobe_shots_prod_dataset[node: download_kobe_shots_prod_dataset]
        end
        subgraph data_ingestion_outputs[outputs]
            direction LR
            raw_kobe_shots_dev_dataset{{output 'raw_kobe_shots_dev': data/01_raw/dataset_kobe_dev.parquet}}
            raw_kobe_shots_prod_dataset{{output 'raw_kobe_shots_prod': data/01_raw/dataset_kobe_prod.parquet}}
        end
        download_kobe_shots_dev_dataset --> raw_kobe_shots_dev_dataset
        download_kobe_shots_prod_dataset --> raw_kobe_shots_prod_dataset
    end
    subgraph data_processing[pipeline: data_processing]
        direction TB
        subgraph data_processing_nodes[nodes]
            direction LR
            preprocess_kobe_shots_dev_node[node: preprocess_kobe_shots]
            preprocess_kobe_shots_prod_node[node: preprocess_kobe_shots_prod]
            create_model_input_table_node[node: create_model_input_table_node]
            split_data_node[node: split_data_node]
        end
        subgraph data_processing_outputs[outputs]
            direction LR
            preprocessed_kobe_shots{{output 'preprocessed_kobe_shots': data/02_intermediate/preprocessed_kobe_shots.parquet}}
            preprocessed_kobe_shots_prod{{output 'preprocessed_kobe_shots_prod': data/02_intermediate/preprocessed_kobe_shots.parquet}}
            model_input_table{{output 'model_input_table': data/03_primary/data_filtered.parquet}}
            base_train{{output 'base_train': data/03_primary/data_filtered.parquet}}
            base_test{{output 'base_test': data/03_primary/data_filtered.parquet}}
        end
        preprocess_kobe_shots_dev_node --> preprocessed_kobe_shots
        preprocess_kobe_shots_prod_node --> preprocessed_kobe_shots_prod
        create_model_input_table_node --> model_input_table
        split_data_node --> base_train
        split_data_node --> base_test
    end
    subgraph data_science[pipeline: data_science]
        direction TB
        subgraph data_science_nodes[nodes]
            direction LR
            train_logistic_regression_model_node[node: train_logistic_regression_model_node]
            train_decision_tree_model_node[node: train_decision_tree_model_node]
            save_logistic_regression_model_plots_node[node: save_logistic_regression_model_plots_node]
            save_decision_tree_model_plots_node[node: save_decision_tree_model_plots_node]
        end
        subgraph data_science_outputs[outputs]
            direction LR
            logistic_regression_model[output 'logistic_regression_model': logistic-regression-model]
            logistic_regression_model_with_proba[output 'logistic_regression_model_with_proba': logistic-regression-model-dev]
            decision_tree_model[output 'decision_tree_model': decision-tree-model]

            logistic_regression_model_plots{{output 'logistic_regression_model_auc': data/08_reporting/logistic_regression_model_auc.png<br/><br/>output 'logistic_regression_model_confusion_matrix': data/08_reporting/logistic_regression_model_confusion_matrix.png<br/><br/>output 'logistic_regression_model_feature_importance': data/08_reporting/logistic_regression_model_feature_importance.png}}

            decision_tree_plots{{output 'decision_tree_auc': data/08_reporting/decision_tree_model_auc.png<br/><br/>output 'decision_tree_model_confusion_matrix': data/08_reporting/decision_tree_model_confusion_matrix.png<br/><br/>output 'decision_tree_model_feature_importance': data/08_reporting/decision_tree_model_feature_importance.png}}
        end
        train_logistic_regression_model_node --> logistic_regression_model
        train_logistic_regression_model_node --> logistic_regression_model_with_proba
        train_decision_tree_model_node --> decision_tree_model
        save_logistic_regression_model_plots_node --> logistic_regression_model_plots
        save_decision_tree_model_plots_node --> decision_tree_plots
    end
    subgraph serving_model[pipeline: serving_model]
        direction TB
        subgraph serving_model_nodes[nodes]
            direction LR
            predict_production_data_node[node: predict_production_data_node]
        end
        subgraph serving_model_outputs[outputs]
            direction LR
            production_data_predictions{{output 'production_data_predictions': data/08_reporting/production_data_predictions.parquet}}
        end
        predict_production_data_node --> production_data_predictions
    end
    data_ingestion --> data_processing
    data_processing --> data_science
    data_science --> serving_model
    data_science --> mlflow_server[ML Flow Models Serve]
    mlflow_server --> streamlit[Streamlit App]
```

### Como as ferramentas Streamlit, MLflow, PyCaret e Scikit-Learn auxiliam na constru√ß√£o dos pipelines?

Rastreamento de Experimentos (Experiment Tracking)

- MLflow √© utilizado para na etapa de rastreamento dos experimentos, registrando hiperpar√¢metros, m√©tricas (no caso deste projeto log_loss e f1_score s√£o m√©tricas sendo registradas), artefatos (como o modelo treinado, plots), vers√µes das depend√™ncias, etc.
- A integra√ß√£o do kedro-mlflow foi utilizada no projeto facilitando o processo de registro dos experimentos por meio da execu√ß√£o das pipelines.

Fun√ß√µes de Treinamento

- PyCaret √© uma ferramenta de AutoML que simplifica a cria√ß√£o, compara√ß√£o, tuning e valida√ß√£o de m√∫ltiplos modelos de classifica√ß√£o.
- O PyCaret tem o Scikit-Learn como depend√™ncia que auxilia na parte do treinamento, prepara√ß√£o dos dados, pr√© e p√≥s-processamento.
- Neste projeto, o PyCaret foi utilizado para separa√ß√£o de treino e teste (nos bastidores √© utilizado o Scikit-learn) e tamb√©m para a parte de treinamento do modelo, assim como obten√ß√£o das m√©tricas que foram posteriormente salvas no MLFlow.

Monitoramento da Sa√∫de do Modelo

- O monitoramento da sa√∫de do modelo pode ser feito por meio da an√°lise de Data Drift, Feature Drift e Concept Drift. Essas mudan√ßas s√£o identificadas atrav√©s de compara√ß√µes estat√≠sticas entre dados hist√≥ricos e novos () e pelo monitoramento cont√≠nuo das m√©tricas de performance.
- Atualmente, estamos registrando as m√©tricas utilizando o MLFlow, ent√£o a cada vers√£o do modelo treinado podemos realizar a compara√ß√£o dessas m√©tricas. Caso a gente queira fazer uma an√°lise mais detalhada de drift, precisar√≠amos fazer a coleta e armazenamento dos dados para podermos aplicar por exemplo testes de Kolmogorov-Smirnov ou Qui-quadrado.

Atualiza√ß√£o de Modelo

- Ao rodar a pipeline `data_science` ocorre o treinamento do modelo e o armazenamento de uma nova vers√£o do modelo treinado no MLFlow Model Registry.
- Uma vez disponibilizada a nova vers√£o pelo MLFlow, podemos servir este modelo com `mlflow models serve -m models:/logistic-regression-model/latest -p 5001`
- Com o Streamlit podemos consumir o modelo. Como estamos passando `latest` ao servir o modelo, garantimos que sempre estaremos consumindo o √∫ltimo modelo dispon√≠vel.

Provisionamento (Deployment)

- O modelo √© versionado e registrado no MLflow Model Registry.
- Pode ser servido via API local com mlflow models serve ou embarcado diretamente na aplica√ß√£o Streamlit, garantindo infer√™ncia direta.
- A interface desenvolvida em Streamlit permite intera√ß√£o com o modelo, visualiza√ß√£o dos dados e resultados das previs√µes.

## Artefatos

### Camada raw ‚Äì Dados brutos

Dados recebidos diretamente da fonte (Github API), sem qualquer tipo de tratamento ou pr√©-processamento. A pipeline utilizada foi `data_ingestion`.

raw_kobe_shots_dev

    Descri√ß√£o: Dataset de desenvolvimento contendo os dados hist√≥ricos de arremessos do Kobe Bryant utilizados para treinamento e valida√ß√£o do modelo.
    - Formato: .parquet
    - Localiza√ß√£o: data/01_raw/dataset_kobe_dev.parquet
    - Colunas:
        - action_type: tipo espec√≠fico do arremesso (ex: Jump Shot, Layup).
        - combined_shot_type: tipo gen√©rico do arremesso (ex: 2PT Field Goal).
        - game_event_id: identificador do evento do jogo.
        - game_id: identificador √∫nico do jogo.
        - lat, lon: coordenadas geogr√°ficas da tentativa.
        - loc_x, loc_y: coordenadas cartesianas da tentativa.
        - minutes_remaining, seconds_remaining: tempo restante no per√≠odo.
        - period: n√∫mero do per√≠odo (1 a 4, ou prorroga√ß√µes).
        - playoffs: flag indicando se √© jogo de playoff.
        - season: temporada (ex: 2010-11).
        - shot_distance: dist√¢ncia do arremesso ao cesto.
        - shot_made_flag: vari√°vel-alvo (1 para acerto, 0 para erro).
        - shot_type, shot_zone_area, shot_zone_basic, shot_zone_range: informa√ß√µes sobre a localiza√ß√£o e tipo do arremesso.
        - team_id, team_name: identificadores do time.
        - game_date: data do jogo.
        - matchup: descri√ß√£o do confronto (ex: LAL vs BOS).
        - opponent: time advers√°rio.
        - shot_id: identificador √∫nico do arremesso.

raw_kobe_shots_prod

    Descri√ß√£o: Dataset de produ√ß√£o contendo novos dados para aplica√ß√£o do modelo treinado. Utilizado na etapa de predi√ß√£o e monitoramento.
    - Formato: .parquet
    - Localiza√ß√£o: data/01_raw/dataset_kobe_prod.parquet
    - Colunas: Mesmo schema do raw_kobe_shots_dev.

#### Camada intermediate ‚Äì Dados pr√©-processados

Conjunto de dados que passaram por etapas de limpeza, transforma√ß√£o e codifica√ß√£o, mas ainda n√£o est√£o preparados para o treino final do modelo.

preprocessed_kobe_shots

    Descri√ß√£o: Dados de desenvolvimento ap√≥s o pr√©-processamento inicial (ex: remo√ß√£o de colunas irrelevantes, tratamento de valores nulos, convers√£o de tipos, encoding de vari√°veis categ√≥ricas).
    - Finalidade: Servir√° como base para gera√ß√£o da tabela de entrada do modelo. Alterei o nome da coluna `lon` para `lng` para atender o especificado no projeto.
    - Formato: .parquet
    - Localiza√ß√£o: data/02_intermediate/preprocessed_kobe_shots.parquet
    - Colunas:
        - action_type: tipo espec√≠fico do arremesso (ex: Jump Shot, Layup).
        - combined_shot_type: tipo gen√©rico do arremesso (ex: 2PT Field Goal).
        - game_event_id: identificador do evento do jogo.
        - game_id: identificador √∫nico do jogo.
        - lat, lng: coordenadas geogr√°ficas da tentativa.
        - loc_x, loc_y: coordenadas cartesianas da tentativa.
        - minutes_remaining, seconds_remaining: tempo restante no per√≠odo.
        - period: n√∫mero do per√≠odo (1 a 4, ou prorroga√ß√µes).
        - playoffs: flag indicando se √© jogo de playoff.
        - season: temporada (ex: 2010-11).
        - shot_distance: dist√¢ncia do arremesso ao cesto.
        - shot_made_flag: vari√°vel-alvo (1 para acerto, 0 para erro).
        - shot_type, shot_zone_area, shot_zone_basic, shot_zone_range: informa√ß√µes sobre a localiza√ß√£o e tipo do arremesso.
        - team_id, team_name: identificadores do time.
        - game_date: data do jogo.
        - matchup: descri√ß√£o do confronto (ex: LAL vs BOS).
        - opponent: time advers√°rio.
        - shot_id: identificador √∫nico do arremesso.

preprocessed_kobe_shots_prod

    - Descri√ß√£o: Vers√£o de produ√ß√£o dos dados pr√©-processados, com as mesmas transforma√ß√µes aplicadas ao dataset de desenvolvimento.
    - Finalidade: Alimentar o modelo final em ambiente de aplica√ß√£o.
    - Formato: .parquet
    - Localiza√ß√£o: data/02_intermediate/preprocessed_kobe_shots_prod.parquet
    - Colunas: mesmo esquema do `preprocessed_kobe_shots`

#### Camada primary ‚Äì Dados prontos para treino/teste

Dados j√° organizados com as features selecionadas, normalizadas e estruturadas para alimentar algoritmos de Machine Learning.

model_input_table

    - Descri√ß√£o: Tabela final com todas as features tratadas, utilizada para separa√ß√£o em treino/teste. Representa o input consolidado para os modelos.
    - Formato: .parquet
    - Localiza√ß√£o: data/03_primary/data_filtered.parquet
    - Dimens√£o: 20285 registros (linhas) e 7 colunas
    - Colunas:
        - lat, lng: coordenadas geogr√°ficas da tentativa.
        - minutes_remaining: tempo restante no per√≠odo.
        - period: n√∫mero do per√≠odo (1 a 4, ou prorroga√ß√µes).
        - playoffs: flag indicando se √© jogo de playoff.
        - shot_distance: dist√¢ncia do arremesso ao cesto.
        - shot_made_flag: vari√°vel-alvo (1 para acerto, 0 para erro).

base_train

    - Descri√ß√£o: Subconjunto da model_input_table contendo os dados utilizados para o treinamento do modelo.
    - Finalidade: Treinar modelos de machine learning com PyCaret.
    - Formato: .parquet
    - Localiza√ß√£o: data/03_primary/base_train.parquet

base_test

    - Descri√ß√£o: Subconjunto da model_input_table contendo os dados utilizados para a avalia√ß√£o do modelo.
    - Finalidade: Calcular m√©tricas como log_loss e f1_score durante o experimento.
    - Formato: .parquet
    - Localiza√ß√£o: data/03_primary/base_test.parquet

ü§ñ Camada data_science ‚Äì Modelos e experimentos

Modelos treinados e salvos com MLflow, prontos para uso em produ√ß√£o ou experimenta√ß√£o. Inclui vers√µes com e sem probabilidade, al√©m dos registros no MLflow Model Registry.

logistic_regression_model

    - Descri√ß√£o: Modelo de regress√£o log√≠stica treinado com scikit-learn, salvo via MLflow para rastreamento.
    - Uso: Vers√£o padr√£o para predi√ß√µes com .predict().
    - Registro no MLflow: logistic-regression-model

logistic_regression_model_with_proba

    - Descri√ß√£o: Mesmo modelo da regress√£o log√≠stica, mas configurado para retornar probabilidades com .predict_proba().
    - Registro no MLflow: logistic-regression-model-dev

logistic_regression_model_dev

    - Descri√ß√£o: Acesso √† √∫ltima vers√£o do modelo de regress√£o log√≠stica registrada no MLflow Model Registry como logistic-regression-model-dev.

decision_tree_model

    - Descri√ß√£o: Modelo de √°rvore de decis√£o treinado e salvo via MLflow.
    - Registro no MLflow: decision-tree-model

Camada reporting ‚Äì Relat√≥rios e visualiza√ß√µes

Artefatos visuais gerados para an√°lise dos modelos, como AUC, matriz de confus√£o e import√¢ncia das vari√°veis.

logistic_regression_model_auc

    - Descri√ß√£o: Gr√°fico de curva ROC AUC do modelo de regress√£o log√≠stica.
    - Localiza√ß√£o: data/08_reporting/logistic_regression_model_auc.png

logistic_regression_model_confusion_matrix

    - Descri√ß√£o: Matriz de confus√£o com desempenho do modelo.
    - Localiza√ß√£o: data/08_reporting/logistic_regression_model_confusion_matrix.png

logistic_regression_model_feature_importance

    - Descri√ß√£o: Gr√°fico de import√¢ncia das features no modelo.
    - Localiza√ß√£o: data/08_reporting/logistic_regression_model_feature_importance.png

decision_tree_model_auc

    - Descri√ß√£o: Gr√°fico de curva ROC AUC da √°rvore de decis√£o.
    - Localiza√ß√£o: data/08_reporting/decision_tree_model_auc.png

decision_tree_model_confusion_matrix

    - Descri√ß√£o: Matriz de confus√£o da √°rvore de decis√£o.
    - Localiza√ß√£o: data/08_reporting/decision_tree_model_confusion_matrix.png

decision_tree_model_feature_importance

    - Descri√ß√£o: Gr√°fico de import√¢ncia das features da √°rvore.
    - Localiza√ß√£o: data/08_reporting/decision_tree_model_feature_importance.png

production_data_predictions

    - Descri√ß√£o: Dataset contendo os resultados das previs√µes feitas com os dados de produ√ß√£o. Inclui os valores reais (y_true), as predi√ß√µes (y_pred), e as m√©tricas de avalia√ß√£o (log_loss e f1_score) aplicadas ao modelo carregado via MLflow.
    - Composi√ß√£o:
        - y_true: Classe real do alvo nos dados de produ√ß√£o.
        - y_pred: Classe prevista pelo modelo.
        - model_log_loss: Valor da fun√ß√£o de custo log_loss calculado com predict_proba.
        - model_f1_score: F1 Score das predi√ß√µes classificadas com .predict().
        - Finalidade: Auxilia na avalia√ß√£o da ader√™ncia do modelo ao novo conjunto de dados e no monitoramento da performance.
        - Formato: .parquet
        - Localiza√ß√£o: data/08_reporting/production_data_predictions.parquet

---

## Import√¢ncia da separa√ß√£o treino e teste

Os dados foram divididos em dois conjuntos, sendo 80% para treino e 20% para teste. Foi utilizado uma divis√£o estratificada e aleat√≥ria garantindo que a propor√ß√£o das classes (shot_made_flag) seja mantida em ambos os conjuntos.

Esta etapa √© essencial para avaliar o desempenho real do modelo. O conjunto de treino √© usado para ajustar os par√¢metros do modelo, enquanto o conjunto de teste permite avaliar sua generaliza√ß√£o em dados nunca vistos.

Estrat√©gias para reduzir vi√©s de dados:

- Estratifica√ß√£o: Garante representatividade balanceada das classes nos conjuntos.
- Cross-validation: O treino do modelo ocorreu usando cross-validation para testar o modelo em m√∫ltiplas parti√ß√µes, reduzindo o risco de overfitting ou vi√©s de amostragem.
- Shuffling aleat√≥rio: Foi utilizado um shuffling para introduzir aleatoriedade e evitar que a ordem original influenciasse no modelo.

## Escolha do modelo

O modelo selecionado foi a Regress√£o Log√≠stica. Foi poss√≠vel observar um melhor desempenho na m√©trica de log_loss, al√©m de uma melhor curva ROC e mais verdadeiros positivos na matriz de confus√£o. Tamb√©m vale destacar a maior simplicidade e interpretabilidade do modelo de regress√£o log√≠stica.

## Ader√™ncia do modelo √† base de produ√ß√£o

Ao realizar a infer√™ncia na base de produ√ß√£o, o desempenho caiu consideravelmente, o que indica que ele n√£o √© aderente √† base de produ√ß√£o. A base de produ√ß√£o cont√©m somente tentativas de arremessos de 3 pontos, enquanto a base de desenvolvimento tem tentativa de arremessos de 2 pontos. Analisando a feature importance, temos a seguinte ordem de maior para menor import√¢ncia no modelo: lat, lng e shot_distance.

Considerando isso, d√° pra notar que s√£o vari√°veis relacionadas com o posicionamento na quadra e dist√¢ncia do arremesso, ou seja, como a base tem um contexto diferente (o posicionamento na quadra para cestas de 2 e 3 pontos s√£o diferentes), ela n√£o consegue generalizar para a base de produ√ß√£o (que n√£o foi utilizada durante o treinamento).

## Monitoramento de sa√∫de do modelo com e sem a disponibilidade da vari√°vel resposta

No caso de termos a vari√°vel resposta, podemos fazer o monitoramento peri√≥dico do desempenho por meio das pr√≥prias m√©tricas log_loss, F1 Score, Precision, Recall, etc., e dessa forma detectar rapidamente a degrada√ß√£o do modelo. Podemos criar um dashboard de desempenho ou formas de receber alertas quando as m√©tricas ca√≠rem abaixo de valores aceit√°veis.

Se a vari√°vel resposta n√£o est√° dispon√≠vel, podemos adotar diferentes estrat√©gias de monitoramento como da distribui√ß√£o de mudan√ßas na distribui√ß√£o dos dados de entrada (data drift), aplicar testes estat√≠sticos como Kolmogorov-Smirnov, monitorar as sa√≠das do modelo (concept drift), etc.

## Estrat√©gias de retreinamento

Estrat√©gia Reativa

- Com base no monitoramento do modelo em produ√ß√£o, pode ser que seja detectada uma degrada√ß√£o no modelo e com base nisso seja necess√°rio um retreinamento, por exemplo, degrada√ß√£o de alguma m√©trica ou se houver algum desvio estat√≠stico nas vari√°veis de entrada. O retreino ocorre ap√≥s a detec√ß√£o do problema.

Estrat√©gia Preditiva

- Periodicamente ocorre o retreino do modelo, podendo incluir dados de fontes diferentes, dados simulados, dados que foram rotulados posterior ao modelo anterior, isso contribui pra manter o modelo atualizado. Se ocorrer uma detec√ß√£o de drift, tamb√©m pode ser feito o retreino. O retreino ocorre por antecipa√ß√£o.
