Projeto de machine learning com o objetivo de prever se Kobe Bryant acertou ou errou uma tentativa de arremesso, utilizando abordagens de classifica√ß√£o e regress√£o. O projeto √© baseado no dataset [Kobe Bryant Shot Selectio](https://www.kaggle.com/c/kobe-bryant-shot-selection/overview), dispon√≠vel no Kaggle.

```mermaid
flowchart
    subgraph data_ingestion[pipeline: data_ingestion]
        direction TB
        get_data[Coleta de dados: request na api do Github] -->
        save_data[Armazenamento dos dados]
        save_data --> raw_kobe_shots_dev_dataset[file: data/01_raw/dataset_kobe_dev.parquet]
        save_data --> raw_kobe_shots_prod_dataset[file: data/01_raw/dataset_kobe_prod.parquet]
    end
    subgraph data_processing[pipeline: data_processing]
        direction TB
        preprocess_kobe_shots[Pr√©-processamento de dados] --> split_data
        split_data[Separa√ß√£o treino e teste] --> save_preprocessed_data[Salvar dados]
        save_preprocessed_data --> intermediate_preprocessed_kobe_shots[file: data/02_intermediate/preprocessed_kobe_shots.parquet]
        save_preprocessed_data --> primary_data_filtered[file: data/03_primary/data_filtered.parquet]
        save_preprocessed_data --> primary_base_train[file: data/03_primary/base_train.parquet]
        save_preprocessed_data --> primary_base_test[file: data/03_primary/base_test.parquet]
    end
    subgraph data_science[pipeline: data_science]
        direction TB
        train_logistic_regression_model[Treinar modelo de regress√£o log√≠stica] --> save_metrics[Salvar m√©tricas do modelo]
        train_decision_tree_model[Treinar modelo de √°rvore de decis√£o] --> save_metrics[Salvar m√©tricas do modelo]
        save_metrics[Salvar m√©tricas do modelo] --> save_model[Salvar modelo]
        save_model --> file_logistic_regression_model[mlflow artifact: logistic_regression_model]
        save_model --> file_decision_tree_model[mlflow artifact: decision_tree_model]
    end
    raw_kobe_shots_dev_dataset --> data_processing
    data_processing --> data_science
```

### Como as ferramentas Streamlit, MLflow, PyCaret e Scikit-Learn auxiliam na constru√ß√£o dos pipelines?

üß™ Rastreamento de Experimentos (Experiment Tracking)

- MLflow √© utilizado para rastrear cada execu√ß√£o (run) dos experimentos, registrando hiperpar√¢metros, m√©tricas (como log_loss e f1_score), artefatos (como o modelo treinado) e vers√µes dos dados e c√≥digo utilizados.
- O Kedro facilita a integra√ß√£o desses experimentos em pipelines reprodut√≠veis e versionados.

‚öôÔ∏è Fun√ß√µes de Treinamento

- PyCaret simplifica a cria√ß√£o, compara√ß√£o, tuning e valida√ß√£o de m√∫ltiplos modelos de classifica√ß√£o com poucas linhas de c√≥digo.
- Scikit-Learn √© utilizado nos bastidores do PyCaret e tamb√©m diretamente para etapas de pr√©-processamento personalizadas ou no p√≥s-processamento.
- As fun√ß√µes de treinamento s√£o integradas ao pipeline do Kedro, que garante modularidade e organiza√ß√£o.

üìà Monitoramento da Sa√∫de do Modelo

- Utilizamos MLflow para registrar m√©tricas de desempenho que ajudam a monitorar a sa√∫de do modelo ao longo do tempo.
- Em produ√ß√£o, a sa√∫de pode ser acompanhada via m√©tricas como log_loss, f1_score, propor√ß√£o de classes previstas, entre outras, comparadas com as dos dados de treino.

üîÅ Atualiza√ß√£o de Modelo

- O pipeline foi estruturado para permitir reexecu√ß√µes programadas ou sob demanda (reativo ou preditivo).
- Altera√ß√µes no conjunto de dados de produ√ß√£o podem ser detectadas com data drift e model drift, sinalizando a necessidade de retreinamento.
- O modelo pode ser atualizado automaticamente com novos dados rotulados, com logs completos sendo mantidos pelo MLflow.

üöÄ Provisionamento (Deployment)

- O modelo √© versionado e registrado no MLflow Model Registry.
- Pode ser servido via API local com mlflow models serve ou embarcado diretamente na aplica√ß√£o Streamlit, garantindo infer√™ncia direta.
- A interface desenvolvida em Streamlit permite intera√ß√£o com o modelo, visualiza√ß√£o dos dados e resultados das previs√µes.
